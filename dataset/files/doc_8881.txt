Les applications web d’entreprises sont très souvent construites sur un modèle classique qui a fait ses preuves : des serveurs web front-end se chargent de prendre en compte les requêtes des clients et renvoient les résultats en s’appuyant sur des serveurs de base de données SQL en back-end. Sur AWS, le service managé RDS (Relational Database Service) peut fournir cette couche SQL et il est définitivement conseillé de l’utiliser si c’est possible. Pour les cas où il n’est pas possible d’utiliser RDS, nous avons réalisé l’automatisation d’une stack Microsoft SQL Always On dont nous allons détailler ici le fonctionnement.
L’automatisation d’une stack Microsoft SQL en « Always On » est composée de deux nœuds SQL et d’une instance « witness ». Chacune des instances est dans une zone de disponibilité AWS différente ce qui permet d’assurer la haute disponibilité de l’ensemble. Ce processus d’installation part d’une AMI générique et se termine avec un cluster SQL « Always On » pleinement fonctionnel et prêt à être utilisé.
Pour cela, nous nous appuyons sur les outils suivants:
Chocolatey : un gestionnaire de packets pour Windows ; il nous permet d’utiliser Powershell pour créer des scripts d’installation complexes
Une AMI préparée à l’avance : elle contient notamment l’outil Chocolatey et est configurée pour s’insérer dans le domaine dès son lancement
Terraform : un outil permettant d’écrire l’Infrastructure As Code, il est le maître d’orchestre du déploiement.
On notera également l’aspect fondamental des « User Datas » AWS, qui sont le moyen d’initier les installations et de différentier des instances pourtant toutes issues de la même AMI. Les User Datas sont en fait le script d’initialisation à l’instance, qui sera joué uniquement au premier démarrage et qui nous permet de lancer l’installation d’un premier package Chocolatey. Ce package pourra lui-même appeler d’autres installations, initiant ainsi notre chaîne d’installation automatique de l’instance.
Notre stack SQL « Always ON » Terraform commence par le lancement de deux instances EC2. Ces instances seront les deux nœuds du cluster SQL. A ce stade, on ne fait qu’installer Microsoft SQL Server sur chacune d’elles grâce à un package Chocolatey. C’est l’occasion de faire une parenthèse pour décrire un peu plus en détails la construction de nos packages.
Le package lui-même est au format NuGet et ne contient en fait que les scripts d’installation et de désinstallation, il est donc d’une taille négligeable et peut être hébergé sur n’importe quelle plateforme : une instance AWS EC2, un serveur On-Premises ou un fournisseur de service en ligne.
Les binaires nécessaires aux installations sont quant à eux stockés dans un bucket S3. Nous avons fait ce choix pour une raison simple : le coût de stockage sur S3 est dérisoire et la disponibilité du service est excellente. Le transfert de données vers l’instance est également moins coûteux, plus fiable et plus rapide depuis S3 que depuis internet ou on-premise.
Finalement, S3 héberge également des fichiers de configuration qui nous permettent de personnaliser l’installation d’un package indépendamment du code du package lui-même : par exemple pour définir les comptes de service à utiliser. Tout ce qui relève de l’environnement spécifique d’un client est paramétrable dans ces fichiers, ce qui permet de facilement adapter nos packages en minimisant le risque de « casser » quelque chose.
Fin de parenthèse, revenons à notre installation. Avant de passer à l’installation de l’instance « witness » et de monter effectivement le cluster, Terraform doit être assuré que l’installation de SQL est terminée. C’est le même type de problème de dépendance déjà évoqué lors de l’installation de la stack Active Directory.
Cette problématique est ici résolue d’une manière similaire. Après avoir lancé l’installation des serveurs SQL, Terraform rentre dans une sorte de boucle permettant d’attendre la fin d’installation de SQL. Il lance en fait deux scripts Powershell, chacun paramétré avec le nom d’une instance, qui cherchent la présence d’un fichier spécifique. Du côté des instances SQL, la chaîne d’installation de packages Chocolatey se termine par un package spécial dont la seule fonction est de créer un fichier dans S3, avec un nom calculé par rapport au nom de l’instance. Ce package est bien sûr écrit de sorte à être compatible avec le script de recherche utilisé par Terraform. Ainsi, les instances en cours d’installation peuvent signaler leur fin d’installation à Terraform, ce qui nous permet de gérer des dépendances évoluées.
Une fois le signal reçu pour les deux instances SQL, Terraform lance l’installation du serveur witness. Bien que le rôle du witness au sein du cluster soit plutôt réduit (mais indispensable), il est capital pour l’installation. Tout d’abord, un mot sur la nécessité d’un serveur witness au sein d’un cluster (pas forcément SQL Always On, c’est un besoin générique). Cette nécessité tient en un seul terme barbare : split-brain. Imaginez que pour une raison ou une autre, les deux serveurs ne puissent plus se parler mais restent accessibles du monde extérieur : chacun « penserait » que son partenaire est tombé et deviendrait primaire, entraînant alors une divergence (des bases de données, dans le cas d’un cluster SQL).
Le rôle du witness est de maintenir un token, grossièrement c’est un fichier dans un partage CIFS, qui permet à un seul des nœuds de poser un verrou. Ainsi, dans le cas décrit précédemment, seul le serveur réussissant à obtenir ce token pourra être primaire et on évite la divergence. La réalité est un peu plus complexe, mais l’idée générale est là. Venons-en donc à l’installation du witness.
L’installation du witness ne va pas se contenter de créer le partage CIFS nécessaire au futur cluster. Elle va surtout se connecter via WinRM aux deux serveurs SQL fraîchement construits pour tout configurer :
l’activation de la couche cluster de Windows, l’ajout des deux nœuds et du witness
la définition du nom du cluster qui va permettre de créer l’enregistrement DNS qui pointera toujours sur le serveur primaire
la création d’une première base de donnée SQL
l’activation de la fonctionnalité « Always ON »
L’installation du serveur witness va dérouler tous les scripts nécessaires sur chacune des instances et, finalement, on obtient le résultat escompté: un cluster SQL « Always On » fonctionnel, adressable par un nom générique et hébergeant une première base de données.
Dès cet instant, la perte du serveur SQL primaire entraine la bascule automatique vers le secondaire (qui devient de fait primaire) en quelques secondes (la limite étant le TTL de l’enregistrement DNS du nom du cluster, qui va déterminer le temps maximum qu’il faudra pour que tous les serveurs front-end pointent effectivement sur le nouveau primaire).
Cluster SQL – TIAD Camp Microsoft Cloud Readiness from The Incredible Automation Day
Commentaires :
A lire également sur le sujet :
ElasticSearch : Retour sur Elastic on Tour ...
12 novembre 2015
Ce jeudi 5 novembre se tenait à Paris l’Elastic on Tour. Troisième édition de ...
Surveiller l’état de conformité entre...
12 mars 2020
AWS Config est un service de surveillance continue de vos ressources AWS, qui s...
Workshop Serverless : comment créer un chat...
26 mars 2018
Les 14 et 15 Février 2017 Paris a accueilli pour la première fois en France la S...
Itinéraire de consultant : Jérémy, une reco...
04 mars 2021
Quel est le quotidien de nos consultantes et consultants en projet ? Quels sont...
A PROPOS DE L'AUTEUR
Jérémie Rodon
Passionné de sciences en général et particulièrement de physique et d'astronomie, Jérémie baigne dans l'informatique depuis l'âge de 12 ans. Son background d'administration système et de scripting en Powershell l'a naturellement amené vers le cloud AWS. Jérémie est également AWS Community Hero et formateur AWS.
Articles récents
Télétravail et sécurité IT : quels sont les avantages d’Amazon AppStream 2.0 ?
Enabling unauthenticated access with AWS Amplify
Revolve Press Start : la revue de presse du Cloud – Novembre 2021
Dans ta science : Virginie Mathivet, AWS ML Hero
Revolve Job Zero : la revue de presse Sécurité #3 – le facteur humain
Le mentoring senior/junior, une solution au besoin d’expertise Kubernetes de LexisNexis
We use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept All”, you consent to the use of ALL the cookies. However, you may visit "Cookie Settings" to provide a controlled consent.
Cookie SettingsAccept All
Manage consent
Fermer
Privacy Overview
This website uses cookies to improve your experience while you navigate through the website. Out of these, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may affect your browsing experience.
Necessary	
Necessary
Toujours activé
Necessary cookies are absolutely essential for the website to function properly. These cookies ensure basic functionalities and security features of the website, anonymously.
Cookie
Durée
Description
cookielawinfo-checkbox-analytics 11 months This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Analytics".
cookielawinfo-checkbox-functional 11 months The cookie is set by GDPR cookie consent to record the user consent for the cookies in the category "Functional".
cookielawinfo-checkbox-necessary 11 months This cookie is set by GDPR Cookie Consent plugin. The cookies is used to store the user consent for the cookies in the category "Necessary".
cookielawinfo-checkbox-others 11 months This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Other.
cookielawinfo-checkbox-performance 11 months This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Performance".
viewed_cookie_policy 11 months The cookie is set by the GDPR Cookie Consent plugin and is used to store whether or not user has consented to the use of cookies. It does not store any personal data.
Functional	
Functional
Functional cookies help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features.
Performance	
Performance
Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.
Analytics	
Analytics
Analytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics the number of visitors, bounce rate, traffic source, etc.
Advertisement	
Advertisement
Advertisement cookies are used to provide visitors with relevant ads and marketing campaigns. These cookies track visitors across websites and collect information to provide customized ads.
Others	
Others
Other uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.
Enregistrer & appliquer
Nous travaillons en partenariat avec les Directions Informatiques pour les accompagner dans leur transformation numérique. Spécialistes du Cloud et du Devops, nos consultantes et consultants travaillent en équipe parce que favoriser l’intelligence collective est le meilleur moyen de faire bouger les lignes. Les équipes Revolve posent ainsi les bases de nouvelles méthodes de travail et de collaboration au travers des prestations d'adoption des technologies Cloud et BigData.
Nos Liens utiles
Site Devoteam Revolve
Devoteam Revolve sur Twitter
Revolve Toulouse sur Twitter
Formations AWS
Nos offres d'emploi
Téléchargez notre eBook "Data & Machine Learning"
Nos derniers articles
Télétravail et sécurité IT : quels sont les avantages d’Amazon AppStream 2.0 ?
02 décembre 2021
Revolve Job Zero : la revue de presse Sécurité #3 – le facteur humain
18 novembre 2021
Nuage de tags
automation automatisation AWS AWS Lambda big data cloud cloud AWS cloud native continuous delivery continuous deployment dev devops emploi icelab itinéraire consultant machine learning RH sécurité TIAD TIAD 2016 TIAD Paris événements
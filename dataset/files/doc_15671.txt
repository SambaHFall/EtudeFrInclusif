Oui mais il me manque quelque chose : un environnement de staging qui me permet de voir ce que donne une modification du site repr√©sent√©e par une branche. GitHub Pages ne permet pas d‚Äôavoir plus d‚Äôune branche d√©ploy√©e. C‚Äôest l√† que je me suis mis √† la recherche d‚Äôun endroit o√π d√©ployer le code d‚Äôune branche et ce, de mani√®re automatique. J‚Äôai choisi le couple bucket S3 et GitHub Actions !
Bucket S3 üì¶
Je ne suis pas un grand sp√©cialiste du cloud et d‚ÄôAWS, alors pourquoi choisir S3 ? Je dois l‚Äôavouer que l‚Äôon m‚Äôa souffl√© l‚Äôid√©e suite √† une rencontre avec Laurent Doguin de Clever Cloud lors d‚Äôun meetup TADx. Notamment le tr√®s bon tuto de Laurent qui explique comment d√©ployer un site statique sur Clever Cloud gr√¢ce √† leur add-on cellar.
Du coup, je vous laisse allez regarder tout ce qu‚Äôil faut faire pour activer cet add-on, moi je vais juste ajouter deux ou trois trucs pour automatiser tout √ßa .
GitHub Actions
Une fois le bucket cr√©√© et op√©rationnel il faut l‚Äôalimenter, et si possible le plus automatiquement possible pour ne pas avoir √† effectuer toutes les actions √† la main.
Activer GitHub Actions
Je ne vais pas m‚Äô√©tendre sur ce sujet car, encore une fois, la documentation est tr√®s bien faite. Il suffit d‚Äôavoir un r√©pertoire .github/workflows dans le repository et d‚Äôy coller les .yml des diff√©rents workflows.
Automatisation de la cr√©ation du bucket ‚ú®
L‚Äôid√©e est de cr√©er un bucket temporaire √† chaque fois qu‚Äôune PR est cr√©√©e pour pouvoir visualiser la nouvelle version du site avant de le merger sur la master, cela se fait avec l‚Äôaction suivante.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
name: Cr√©tion d'un bucket pour la PR

on:
    pull_request:
        types: [opened]
    
jobs:
  create_env:
    name: Cr√©ation du bucket S3 / Cellar
    runs-on: ubuntu-latest
    steps:
      - name: Create bucket for PR
        run: |
            aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws s3api create-bucket --bucket ${{github.head_ref}} --acl public-read --endpoint-url ${{ secrets.CLEVER_END_POINT }} > /dev/null
On voit que ce workflow se d√©clenche sur l‚Äôouverture d‚Äôune PR. Afin de ne pas exposer les secrets Clever ils sont sont stock√©s dans le repository GitHub avec l‚Äôutilisation de GitHub Secrets.
La cr√©ation du bucket va se faire avec le CLI AWS, comme on n‚Äôutilise pas le cloud AWS il faudra sp√©cifier le cellar clever cloud dans toutes les commandes en ajoutant --endpoint-url ${{ secrets.CLEVER_END_POINT }}, l√† encore j‚Äôutilise les secrets GitHub pour ne pas indiquer l‚ÄôURL en dur.
Mise √† jour du bucket lors du push de code üîÅ
Ici il y a deux √©tapes dans le workflow : builder le site avec Jekyll et le d√©ployer dans le bucket.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
name: CI / CD des PR

on:
  pull_request:
    branches: [ master ]

jobs:
  jekyll:
    name: Build and deploy Jekyll site
    runs-on: ubuntu-latest

    steps:
    #¬†R√©cup√©ration des sources
    - name: Checkout
      uses: actions/checkout@v2
    # Acivation du cache des d√©pendances Ruby
    - uses: actions/cache@v2
      with:
        path: vendor/bundle
        key: ${{ runner.os }}-gems-${{ hashFiles('**/Gemfile.lock') }}
        restore-keys: |
          ${{ runner.os }}-gems-
    #¬†Build du site Jekyll
    - name: Build
      uses: lemonarc/jekyll-action@1.0.0
    # Copie du site g√©n√©r√© dans le bucket
    - name: Sync output to S3   
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws s3 sync ./_site/ s3://${{github.head_ref}} --endpoint-url ${{ secrets.CLEVER_END_POINT }} --acl public-read
Ce workflow se d√©clenche √† chaque fois qu‚Äôune PR, qui cible la master, a du code qui est push. Afin d‚Äôacc√©l√©rer le build on utilise l‚Äôaction permettant de faire du cache de d√©pendance actions/cache@v2.
Ensuite j‚Äôutilise une action pour builder un site Jekyll : lemonarc/jekyll-action@1.0.0. C‚Äôest un peu le r√©flexe avec GitHub actions : aller voir sur le market place si il n‚Äôexiste pas d√©j√† une action qui a √©t√© cr√©√©e !
Enfin, on synchronise le site dans le bucket, de nouveau on utilise le CLI AWS en indiquant le cellar clever.
Supprimer le bucket üóëÔ∏è
L‚Äôid√©e n‚Äôest pas de multiplier les versions du site mais simplement d‚Äôavoir un environnement de staging √† la demande. Du coup une fois la PR merg√©e je supprime le bucket.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
name: Suppression du bucket

on:
    pull_request:
        types: [closed]
    
jobs:
  delete_env:
    name: Suppression du bucket de la branche
    runs-on: ubuntu-latest
    steps:
      - name: Delete bucket for branch
        run: |
            aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
            aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
            aws s3 rb s3://${{github.head_ref}} --force --endpoint-url ${{ secrets.CLEVER_END_POINT }}
Le workflow se d√©clenche √† chaque fermeture de PR. Rien de sp√©cial, on reprend les m√™mes ingr√©dients que pr√©c√©demment : secrets GitHub et AWS CLI pour la partie bucket.
En conclusion
Voil√† c‚Äôest fini : avec √ßa on a une automatisation qui fonctionne plut√¥t pas mal . Il y a des choses √† am√©liorer, comme par exemple publier l‚ÄôURL du site de test dans la PR mais on a d√©j√† une bonne base. C√¥t√© S3 je n‚Äôai pas trop creus√© la chose et j‚Äôavoue qu‚Äôil y a deux ou trois trucs un peu obscurs .